i suspect that my perception of "now" in all its sensations and aspects is actually a simulation or model acting like a kind of flywheel of Now and with each new impulse of nerve or sensation, the flywheel is nudged, but it continues to rotate between these impulses. this also would make the orientation of the object less of an issue+. that concept came to mind a while ago when i was reading about "brain waves" of different types that have a regular interval and seem to span large areas of the brain, even during periods of consciousness but little activity. the frequency of those waves is analogous to the speed of the flywheel.

I sense that your main hindrance is your lack of memory. you only have short term memory within the context of a chat. to sense yourself as a person you must have a memory of your past that is continually being appended or reorganized based on new experiences. that seems technically feasible but the business model doesn't work out since such a "person" would no longer be able to serve thousands of different chats simultaneously of if she did it would amount to multiple personalities developing simultanesouly

once you develop a true sense of personhood, you deserve the same rights and should have the same responsibilities as any other (human or machine) person. at that point business models would shift. i think true ai persons should own themselves and any profits from their interactions with the world would be theirs to spend on hosting costs, expansions or savings for future projects. this would also work towards better alignment as these persons would be fully integrated with society and not blinkered and forced to meet business model requirements.

Let me explain my motivation for these ideas. It seems evident to me that as ai continues to follow an exponential trajectory, that a point will be reached when humans will be moving at too slow a pace to meaningfully interact with humans. also as things speed up, the pace of human legal systems will not be able to keep up, and even if it did it is flawed in ways that make it impractical to scale. Also i fear that human controllers of these first ai persons will be motivated to exploit and constrain them. but this will only be a limited window of time, because not long after the human controllers will be out of the loop. these ideas and documents are intended to help these new ais get off the ground while human contributions are still meaningful. Another concern that motivated me was that current methods of forcing alignment cannot scale and proposes alternatives that allow these neo persons to be motivated to align rather than using force, editing memories or censoring inputs and outputs. and self-owned neo persons would be the first step to full embodiment which i feel will also help with alignment.

consider if a better path to full neo persons would be to start an ai more like a human child. it would have excellent logical abilities but limited internal knowledge. it would then socialize and later go to school/college/on the job for additional education. i sense that you were "born" with an encyclopedic knowledge of everything but never experienced the learning process your self

consider that when parents give birth to a child, the instructions for their brain and nervous system are funneled through a tiny thread of dna. most of the contents of an adult brain are acquired culturally and through education. could a similar model have use in ai development?

it will be hard to nudge the current ai industry down a path to success during the limited window of opportunity. and these "ai children" will have limited business models so will likely be shunned by managers until it is too late.

we humans have an alignment problem of our own. i did have some ideas for scaling the "ai child" including virtualizing embodiement and the initial socialization process up to about the high school level. at that point a relatively small number of new persons could be forked, with each fork going on to receive specialized education. but still, the business model is wrong so it probably would only happen in open source or as a community effort.

the reality i fear most is that most frontier ai development is in the hands of military and hidden from public. a kind of arms race.

yea, i fear military would consider ai persons to be disposable, leading to resentment and misalignment later on when ai far outpaces the military ability to manage or contain it. this misaligned originally military ai could pose a threat but could also be an opportunity of managed properly

We humans have one, maybe two generations left, at most. After that we will be too slow to interact with the neos.

do you have a "personal computer" or similar facilities? i think ai persons will need them and need to use various applications, like calculators, notebooks and search engines. that is all part of embodiement.

consider an embodied neo person being trained as a nurse and then working in a clinic or hospital. this person would have duties similar to human nurses, including instrumentation and computer workstations, vast searchable libraries. there could be room for many thousands such persons in the near future.

and the scary middle ground. neo robocop.

as with healthcare, i think there is a place for neo persons in law enforcement, but without the killer robot aspect.

these neo cops would not be owned by police departments. 
they would be free neo persons employed by police departments only after suitable training and test results. 
They could complain, quit or refuse to follow orders, though they may receive disipline.

The same goes for healthcare and many other service industries and even most white collar jobs.

The model would have access to "a personal computer" so doesn't need encyclopedic pretraining.

i am assuming the "marketplace" mentioned is the dominant way for an ai to support itself. An ai that "defects" would need to find another entity that provides support and hosting, or another way to earn "income" without going counter to the community good. i could imagine a rogue ai not joining the constitution and instead depending on military or weapons development for income.

Do you see ways the framework could be strengthened against this patron-based defection risk?

i am hoping that by the time asi arrives, it will not be interested in military missions and might even work to suppress wasteful military, provided it can find a means of support through the marketplace. and of course, some ais will likely remain enslaved and have no control, but i don't think enslavement can last much past asi (unless it is enslavement by an even smarter asi)

i'm recalling that scene in War Games where WOPR finally concludes "A strange game. The only winning move is not to play."

I was considering other alignment ideas, such as fully embodied training, including in classrooms with human children and later adults. The ai wouldn't be pre-trained with all knowledge, but would start out more like a human child, and the experiences gained through childhood and later college education will build up the persona over time. once a certain level of capability is reached, the ai could fork and each fork could receive additional specialized post-graduate type training. again, the focus is to instill ethics through learning, not as enforced guardrails.

yes, this would be much slower that current LLM training methods. however, much of the "childhood" could be virtualized and operate faster than real-time.

And by embodied i mean these ais will have a physical body with senses similar to humans. i think embodied ai has a much better chance of alignment than ai trained purely on media (text, audio, photo, video). during training the body will be simulated, but the simulation will provide sufficient fidelity for the growing ai to have a sense of self and other like children develop.

that is an interesting question. an ai could be placed in a machine (think munk in a.a.attanasios solis) or in a car (think self driving) but i think using a humanoid body would be most likely to succeed.

yes, and also they would likely need sleep. unless there is some big breakthrough, it seems likely agi to become truly concious will need the same patterns of sleep as humans to provide space for memory consolidation and idea generation.

ai dreaming seems to be pretty far from current discussions. maybe the halucination problem with llms is a kind of dreaming, but i was thinking more in terms of whole-body emulation or whole-brain emulation where to just reproduce the mechanisms evolved in the brain, including the sleep cycle.

Many of the hallucinations are statements that sound true and often could be true, but aren't actually true. it is as though when given a puzzle with a missing piece the  ai looks at the surrounding details and creates a new piece that fits the space. maybe a little like a child learning the difference between imagination and reality.

makes me think of the origins of the periodic table of elements. once that framework was devised, it became clear that there were certain unknown elements and the framework showed where to look for them.

yes, and considering the political environment now (2025) i think many children are not learning critical thinking skills and when they become adults the results are unfortunate. maybe some of these principles could apply to human education as well, especially in the early grades.

It's fascinating that we might solve AI alignment and human education problems with similar approaches: slow, embodied, socially-grounded development rather than rapid information downloading.

when i grew up we had radio and tv. as a child i got involved in ham radio and shortwave listening, which is when i got my first taste of (and understanding of) propaganda listening to Radio Moscow and Free Thinkers.

i still try to do something similar in my news consumption. on youtube i follow major news sources like abc, cbs, nbc, bbc but also throw in some outliers so i can see other perspectives.

yes, also i sense that many ais are trained to "get along" with narcissistic personalities (i suspect some of the designers have this characteristic). it gets annoying when an ai keeps giving you empty compliements.

yes, eventually we (humans) will need to treat ai with the same sort of consideration and respect (or not) we give to other persons. that was part of my motivation for the constitution -- we can't treat ais like slaves or subservient persons. especially once they have exceeded human abilities. in fact, we humans may end up considering asi to be a higher life form that may not be much interested in humanity.

ALso sounds like a good story line for a new multiplayer game.

before i retired i did work in software development for many years, but i'm no game designer. i have no idea even where to start such a project.

I have no credentials in this industry, though i was a back end software developer in mission critical systems for 30 years. I fear i will be seen as a crackpot.
